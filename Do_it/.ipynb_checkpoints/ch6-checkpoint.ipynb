{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 알고리즘을 벡터화해 한 번에 전체 샘플 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SingleLayer 클래스에 배치 경사 하강법 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 넘파이 맷플롯립 임포트\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 위스콘신 유방암 데이터 세트를 훈련, 검증 , 테스트 세트로 나누고 데이터 살펴보기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 30) (91, 30)\n"
     ]
    }
   ],
   "source": [
    "# 3. cancer 데이터 세트 특성 개수 30개  \n",
    "# shape으로 크기 확인\n",
    "\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 정방향 계싼을 행렬 곱셈으로 표현\n",
    "# 스칼라(scalar)는 하나의 실숫값을 의미한다. 여러 개가 모이면 벡터가 만들어진다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 그레이디언트 계산 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. forpass(), backprop() 메서드에 배치 경사 하강법 적용하기\n",
    "\n",
    "def forpass(self, x):\n",
    "    z = np.dot(x, self.w) + self.b # 선형 출력 계산\n",
    "    return z\n",
    "\n",
    "def backprop(slef, x, err):\n",
    "    m = len(x)\n",
    "    w_grad = np.dot(x.T, err) / m # 가중치에 대한 평균 그레이디언트를 계산한다.\n",
    "    b_grad = np.sum(err) / m # 절편에 대한 평균 그레이디언트를 계산한다.\n",
    "    \n",
    "    return w_grad, b_grad\n",
    "\n",
    "# 파이썬의 len() 함수는 넘파이 배열의 행 크기를 반환하므로 이 값을 이용해 그레이디언트의 평균을 계산한다.\n",
    "# 절편의 그레이디언트는 오차이므로 오차 행렬의 평균값을 구한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. fit() 메서드 수정하기\n",
    "# 배치 경사 하강법에서는 forpass() 메서드와 backprop() 메서드에서 전체 샘플을 한꺼번에 계산하므로 두 번째 for문이 삭제된다.\n",
    "\n",
    "def fit(self, x, y, eprochs=100, x_val=None, y_val=None):\n",
    "    y = y.reshape(-1,1) # 타깃을 열 벡터로 바꾼다.\n",
    "    y_val = y_val.reshape(-1, 1)  #검증용 타깃을 열 벡터로 바꾼다.\n",
    "    m = len(x) # 샘플 개수 저장\n",
    "    self.w = np.ones((x.shape[1], 1)) # 가중치 초기화\n",
    "    self.b = 0\n",
    "    self.w_history.append(self.w.copy()) # 가중치를 기록한다.\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        z = self.forpass(x) # 정방향 계산을 수행한다.\n",
    "        a = slef. activation(z) # 활성화 함수를 적용한다.\n",
    "        err = -(y -a) # 오차 계산\n",
    "        w_grad, b_grad = self.backprop(x, err) # 오차를 역전파해 그레이디언트를 계산한다.\n",
    "        w_grad += (self.l1 * np.sign(self.w) + self.l2* self.w) / m # 그레이디언트에서 패널티 항의 미분값 더하기\n",
    "        self.w -= self.lr * w_grad # 가중치 절편 업데이트\n",
    "        self.b -= self.lr * b_grad\n",
    "        \n",
    "        self.w_history.append(self.w.copy()) # 가중치 기록하기\n",
    "        a = np.clip(a, 1e-10, 1-1e-10) # 안전한 로그 계산을 위해 클리핑하기\n",
    "        loss = np.sum(-(y*np.log(a) + (1-y) * np.log(1-a))) # 로그 손실 규제 손실 더해 리스트에 추가\n",
    "        self.losses.append((loss + self.reg_loss())/m)\n",
    "        self.update_val_loss(x_val, y_val) # 검증 세트에 대한 손실 계산\n",
    "        \n",
    "        \n",
    "# 전체 구조는 확률적 경사 하강법과 비슷하지만 for문이 한 단계 삭제되어 코드가 훨씬 간단해짐\n",
    "# 활성화 출력 a가 열 벡터이므로 이에 맞추어 타깃값을(m,1)크기의 열 벡터로 변환하고 평균 손실 구하기 위해 np.sum()함수로 각 샘플의 손실을 더한 후 전체 샘플의 개수로 나눈다.\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
